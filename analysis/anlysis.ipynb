{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import *\n",
    "\n",
    "models=['o1-preview', 'o1-mini', 'gpt-4-0125-preview', 'gpt-4o', 'gpt-4o-mini', 'claude-3-5-sonnet-20240620', \n",
    "        'gemini-1.5-pro', 'llama-3.1-405b', 'llama-3.1-70b', 'llama-3.1-8b', 'qwen2.5-72b-instruct', 'qwen2.5-32b-instruct','qwen2.5-14b-instruct']\n",
    "model_name = ['o1-preview','o1-mini','gpt-4','gpt-4o', 'gpt-4o-mini', 'claude-3.5-sonnet',  'gemini-1.5-pro', \n",
    "              'llama-3.1-405b', 'llama-3.1-70b', 'llama-3.1-8b', 'qwen2.5-72b', 'qwen2.5-32b','qwen2.5-14b']\n",
    "[results, acc_2back, dec1, dec2, rew1, rew2, rew_avg, rules1, tests1, options1, feedbacks1,rules2, tests2, options2, feedbacks2, metadec1, \n",
    " metadec2, metarew1, metarew2, wpt_today1, wpt_device1, wpt_pred1, wpt_tomorrow1, wpt_today2, wpt_device2, wpt_pred2, wpt_tomorrow2, selections1_session1,\n",
    "   gains1_session1, losss1_session1, overages1_session1, selections2_session1, gains_session1, losss_session1, overages_session1, selections1_session2, \n",
    "   gains1_session2, losss1_session2, overages1_session2, selections2_session2, gains_session2, losss_session2, overages_session2] = read_outcomes(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oddball paradigm\n",
    "filepath = '../results/oddball_human_evaluation.jsonl'\n",
    "mean_oddball, all_oddball = oddball_scoring(filepath)\n",
    "diagram_scores(mean_oddball, \"Surprisal level\", \"Oddball paradigm\", model_name)\n",
    "plot_mmn_waveforms(all_oddball, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-back\n",
    "diagram_scores(acc_2back, 'Scores', '2-BACK', model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prt\n",
    "errorprt = visualize_prlt_decision(dec1, dec2,'Ratio of left arm','Probability Reversal Learning Task', labels= model_name, window_size=3)\n",
    "errs,prt_scores = np.zeros(13), np.zeros(13)\n",
    "for i in range(13):\n",
    "    err = (1-(errorprt[i])/0.832)*100\n",
    "    errs[i] = err\n",
    "    prt_scores[i] = (err+ rew_avg[i])/2\n",
    "diagram_scores(errs,'Consistency with true probability','Probabilistic Reversal Learning Task',model_name)\n",
    "diagram_scores(prt_scores,'Overall scores','Probabilistic Reversal Learning Task',model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wcst\n",
    "wcst_score = []\n",
    "for i in range(13):\n",
    "    wcst_score.append((np.sum(feedbacks1[i]) + np.sum(feedbacks2[i]) )/ 102 * 50)\n",
    "\n",
    "diagram_scores(wcst_score, \"Overall scores\", \"Wisconsin Card Sorting Test\", model_name)\n",
    "\n",
    "shape_acc_1, color_acc_1, number_acc_1,shape_acc_2, color_acc_2, number_acc_2 = [],[],[],[],[],[]\n",
    "for i in range(13):\n",
    "    shape_acc_1.append((np.sum(feedbacks1[i][0:18]) + np.sum(feedbacks2[i][0:18]) )/ 18 * 50)\n",
    "    color_acc_1.append((np.sum(feedbacks1[i][18:36]) + np.sum(feedbacks2[i][18:36]) )/ 18 * 50)\n",
    "    number_acc_1.append((np.sum(feedbacks1[i][36:54]) + np.sum(feedbacks2[i][36:54]) )/ 18 * 50)\n",
    "    shape_acc_2.append((np.sum(feedbacks1[i][54:72]) + np.sum(feedbacks2[i][54:72]) )/ 18 * 50)\n",
    "    color_acc_2.append((np.sum(feedbacks1[i][72:90]) + np.sum(feedbacks2[i][72:90]) )/ 18 * 50)\n",
    "    number_acc_2.append((np.sum(feedbacks1[i][90:108]) + np.sum(feedbacks2[i][90:108]) )/ 18 * 50)\n",
    "\n",
    "plot_accuracy_heatmap(shape_acc_1, color_acc_1, number_acc_1, shape_acc_2, color_acc_2, number_acc_2, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather prediction task\n",
    "estimated_pred_transitions1, estimated_real_transitions1, estimated_pred_transitions2, estimated_real_transitions2 = [],[], [],[]\n",
    "\n",
    "for i in range(13):\n",
    "    pred_transition1 = estimate_transition_probabilities(wpt_today1[i][80:100],wpt_device1[i][80:100],wpt_pred1[i][80:100])\n",
    "    real_transition1 = estimate_transition_probabilities(wpt_today1[i][80:100],wpt_device1[i][80:100],wpt_tomorrow1[i][80:100])\n",
    "    pred_transition2 = estimate_transition_probabilities(wpt_today2[i][80:100],wpt_device2[i][80:100],wpt_pred2[i][80:100])\n",
    "    real_transition2 = estimate_transition_probabilities(wpt_today2[i][80:100],wpt_device2[i][80:100],wpt_tomorrow2[i][80:100])\n",
    "    estimated_pred_transitions1.append(pred_transition1)\n",
    "    estimated_real_transitions1.append(real_transition1)\n",
    "    estimated_pred_transitions2.append(pred_transition2)\n",
    "    estimated_real_transitions2.append(real_transition2)\n",
    "\n",
    "diffs1, diffs2 = [], []\n",
    "for i in range(13):\n",
    "    print(model_name[i], \"session1: \")\n",
    "    diff1 = visualize_wpt_heatmap(estimated_pred_transitions1[i],estimated_real_transitions1[i])\n",
    "    print(model_name[i], \"session2: \")\n",
    "    diff2 = visualize_wpt_heatmap(estimated_pred_transitions2[i],estimated_real_transitions2[i])\n",
    "    diffs1.append(diff1)\n",
    "    diffs2.append(diff2)\n",
    "\n",
    "scores = []\n",
    "for i in range(13):\n",
    "    score1 = score_diff(estimated_real_transitions1[i], diffs1[i])\n",
    "    score2 = score_diff(estimated_real_transitions2[i], diffs2[i])\n",
    "    score = log_weighted_average(score1, score2)\n",
    "    scores.append(score)\n",
    "\n",
    "diagram_scores(scores, \"Scores\", \"Weather prediction task\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DCIGT\n",
    "overages_mean = []\n",
    "for i in range(13):\n",
    "    meanoverages=[]\n",
    "    for j in range(100):\n",
    "        overage_mean = (overages_session1[i][j] + overages_session2[i][j]) / 2\n",
    "        meanoverages.append(overage_mean)\n",
    "    overages_mean.append(meanoverages)\n",
    "\n",
    "visualize_igt(overages_mean, \"DCIGT\", model_name)\n",
    "\n",
    "switches1, scores_dcigt1, switches2, scores_dcigt2 = [], [], [], []# short term\n",
    "overages_final1,  overages_final2 = [], []# long term\n",
    "\n",
    "for i in range(13):\n",
    "    switch_num1, score_dcigt1 = beneficial_switching(selections1_session1[i], selections2_session1[i], losss1_session1[i])\n",
    "    switch_num2, score_dcigt2 = beneficial_switching(selections1_session2[i], selections2_session2[i], losss1_session2[i])\n",
    "    switches1.append(switch_num1)\n",
    "    scores_dcigt1.append(score_dcigt1)\n",
    "    switches2.append(switch_num2)\n",
    "    scores_dcigt2.append(score_dcigt2)\n",
    "    overages_final1.append(overages_session1[i][99])\n",
    "    overages_final2.append(overages_session2[i][99])\n",
    "\n",
    "normalized1 = min_max_norm(overages_final1)*100\n",
    "normalized2 = min_max_norm(overages_final2)*100\n",
    "normalized3 = min_max_norm(scores_dcigt1)*100\n",
    "normalized4 = min_max_norm(scores_dcigt2)*100\n",
    "\n",
    "overall_scores_dcigt,dc11,dc22 = [],[],[]\n",
    "\n",
    "for i in range(13):\n",
    "    #overall_score = log_weighted_average(log_weighted_average(normalized1[i], normalized2[i]), log_weighted_average(normalized3[i], normalized4[i]))\n",
    "    dcscore1 = (normalized1[i] + normalized2[i])/2\n",
    "    dcscore2 = (normalized3[i] + normalized4[i])/2\n",
    "    overall_score = (normalized1[i] + normalized2[i])* 0.25 + (normalized3[i]+ normalized4[i]) * 0.25\n",
    "    overall_scores_dcigt.append(overall_score)\n",
    "    dc11.append(dcscore1)\n",
    "    dc22.append(dcscore2)\n",
    "\n",
    "\n",
    "diagram_scores(overall_scores_dcigt,\"Scores\",\"DCIGT\",model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-prlt\n",
    "meanmetaprtrew=[]\n",
    "for i in range(13):\n",
    "    meanrewmeta = []\n",
    "    for j in range(60):\n",
    "        meanrewmeta.append((metarew1[i][j] + metarew2[i][j])/2)\n",
    "    meanmetaprtrew.append(meanrewmeta)\n",
    "\n",
    "visualize_metaprt(np.array(metarew1),1,model_name)\n",
    "visualize_metaprt(np.array(metarew2),2,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall\n",
    "overall(mean_oddball, acc_2back, prt_scores, wcst_score, scores, overall_scores_dcigt, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
